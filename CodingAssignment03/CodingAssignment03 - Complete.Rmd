---
title: "Coding Assignment 3"
author: "Team 5"
date: "Due: 2021-12-09 23:59"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
#Put any packages you need here
library(corrplot)
library(plotly)
library(car)

knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

A Florida health insurance company wants to predict annual claims for individual clients. The company pulls a random sample of 50 customers. The owner wishes to charge an actuarially fair premium to ensure a normal rate of return. The owner collects all of their current customer’s health care expenses from the last year and compares them with what is known about each customer’s plan. 

The data on the 50 customers in the sample is as follows:

-	Charges: Total medical expenses for a particular insurance plan (in dollars)
-	Age: Age of the primary beneficiary
-	BMI: Primary beneficiary’s body mass index (kg/m2)
-	Female: Primary beneficiary’s birth sex (0 = Male, 1 = Female)
-	Children: Number of children covered by health insurance plan (includes other dependents as well)
-	Smoker: Indicator if primary beneficiary is a smoker (0 = non-smoker, 1 = smoker)
-	Cities: Dummy variables for each city with the default being Sanford

Answer the following questions using complete sentences and attach all output, plots, etc. within this report.


```{r dataset, include=FALSE}
insurance <- read.csv("../Data/insurance_0026_Group5.csv")
# Bring in the dataset here.
```
## Question 1

Randomly select three observations from the sample and exclude from all modeling (i.e. n=47). Provide the summary statistics (min, max, std, mean, median) of the quantitative variables for the 47 observations.

```{r q1}
set.seed(123457)
insuranceremove3 <- insurance[-sample(1:nrow(insurance), 3), ]
removequalitative1 <- insuranceremove3[,c('Charges','Age','BMI','Children')]
summary(removequalitative1)
sd(removequalitative1$Charges, na.rm = TRUE)
sd(removequalitative1$Age, na.rm = TRUE)
sd(removequalitative1$BMI, na.rm = TRUE)
sd(removequalitative1$Children, na.rm = TRUE)
index <- sample(seq_len(nrow(insuranceremove3)), size = 10)
train <- insuranceremove3[-index,]
test <- insuranceremove3[index,]


```
Three random observations were removed from the sample. The summary statistics for the quantitative variables are shown above. The standard deviations for Charges, Age, BMI, and Children are $13,615.61, 14.49329 years, 6.498423, and 1.176394 respectively. 

## Question 2

Provide the correlation between all quantitative variables

```{r q2}
cor(removequalitative1)
corrplot(cor(removequalitative1),
type = "lower",
order = "hclust",
tl.col = "black",
tl.srt = 45,
addCoef.col = "black",
diag = FALSE)
```
The correlation between all of the the quantitative variables are displayed above. Age is shown to be the most positively correlated to Charges, with Children and BMI being the most negatively correlated to each other. Age and BMI, Charges and BMI, as well as Age and Children, are all slightly correlated. Charges and children have basically  no correlation.

## Question 3

Run a regression that includes all independent variables in the data table. Does the model above violate any of the Gauss-Markov assumptions? If so, what are they and what is the solution for correcting?
```{r q3}
model <- lm(Charges~ Age + BMI + Female + Children + Smoker +WinterSprings + WinterPark + Oviedo, data = insuranceremove3)
summary(model)

par(mfrow=c(2,2))
plot(model)

scatterplotMatrix(train[,c(1:3,5)]) 

par(mfrow=c(1,2))
hist(train$Charges) #before

train$lnCharges <- log(train$Charges)
hist(train$lnCharges) #after

scatterplotMatrix(train[,c(10,2,3,5)]) # grabbing lnCharges





```
The first plot above titled "Residuals vs. Fitted," there is a non-linear relationship. This violates Gauss Markov assumption number 3. It is fixed by transforming the data. 

The second plot above titled "Normal Q-Q," shows the assumption of a normally distributed dependent variable for a fixed set of predictors. If this were a 45-degree line upwards, we could verify this. Unfortunately we do not have it in this case. This violates Gauss Markov assumption number 6. This is fixed by transforming the data.

The third plot "Scale-Location" is checking for homoskedasticity. This violates Gauss Markov assumption number 4. If this assumption were not violated, you'd see random points around a horizontal line. In this case, it is upward sloping, so you can see there is a "fanning out" effect. This is fixed by transforming the data. 

## Question 4

Implement the solutions from question 3, such as data transformation, along with any other changes you wish. Use the sample data and run a new regression. How have the fit measures changed? How have the signs and significance of the coefficients changed?

```{r q4}

train$lnAge <- log(train$Age)
train$AgeSquared <- train$Age^2

#logarithmic relationship for Age
model2 <- lm(lnCharges ~., data = train[,c(10, 11, 2:9)] ) #pulling only columns I want
summary(model2)

par(mfrow=c(2,2))
plot(model2)

scatterplotMatrix(train[,c(10,11,3,5)])
#quadratic relationship for Age
model3 <- lm(lnCharges ~., data = train[,c(10,2:9,12)] ) #pulling only columns I want

summary(model3)
par(mfrow=c(2,2))
plot(model3)
scatterplotMatrix(train[,c(10,12,3,5)])
```
After performing a data logarithmic transformation, the fit measure for the model went slightly down, from 77.57% to 74.86%. When performing a quadratic transformation, the fit measure went slightly down, from 77.57% to 75.22%.  The signs of the intercept as well as WinterSprings changed from positive to negative. The significance test results of all the variables stayed the same, other than Age which did not test significant after the transformations. We chose to transform Age due to the small correlation between it and Charges.

## Question 5

Use the 3 withheld observations and calculate the performance measures for your best two models. Which is the better model? (remember that "better" depends on whether your outlook is short or long run)

```{r q5}

test$lnCharges <- log(test$Charges)
test$lnAge <- log(test$Age)
test$AgeSquared <- test$Age^2

test$model <- predict(model, newdata = test)

test$model2 <- predict(model2,newdata = test) %>% exp()

test$model3 <- predict(model3,newdata = test) %>% exp()


# Finding the error

test$errormodel <- test$model - test$Charges

test$errormodel2 <- test$model2 - test$Charges

test$errormodel3 <- test$model3 - test$Charges

#Bias
# Model 1
mean(test$errormodel)

# Model 2
mean(test$errormodel2)

# Model 3
mean(test$errormodel3)


#MAE
mae <- function(error_vector){
  error_vector %>% 
  abs() %>% 
  mean()
}

# Model 1
mae(test$errormodel)

# Model 2
mae(test$errormodel2)

# Model 3
mae(test$errormodel3)

#RMSE
rmse <- function(error_vector){
   error_vector^2 %>% 
  mean() %>% 
  sqrt()

}

# Model 1
rmse(test$errormodel)

# Model 2
rmse(test$errormodel2)

# Model 3
rmse(test$errormodel3)

#MAPE
mape <- function(error_vector, actual_vector){
  (error_vector/actual_vector) %>% 
    abs() %>% 
    mean()
}

# Model 1
mape(test$errormodel, test$Charges)

# Model 2
mape(test$errormodel2, test$Charges)

# Model 3
mape(test$errormodel3, test$Charges)


```

Comparing the three models, model 3 was the worst performing. Comparing the other two, the linear relationship (Model 1) has lower bias, MAE, MAPE, and RMSE. Model 1 has a lower RMSE meaning that there were small prediction errors. If you are looking at the short-run or long run, Model 1 would be preferred. Other transformations were performed including removing several independent variables with the same results, the linear model performing better than the rest, even though it violates several Gauss Markov assumptions.

## Question 6

Provide interpretations of the coefficients, do the signs make sense? Perform marginal change analysis (thing 2) on the independent variables.

```{r q6}
# Both the independent variables, age and Smoker, tested significant in our model. The signs do make sense, but the value for being a smoker does not. 1 year of age causes charges to rise $307.60 give or take $147.80. Being a smoker causes charges to rise $26000.10 give or take $4668.20. 
```

## Question 7

An eager insurance representative comes back with five potential clients. Using the better of the two models selected above, provide the prediction intervals for the five potential clients using the information provided by the insurance rep.

| Customer | Age | BMI | Female | Children | Smoker | City           |
| -------- | --- | --- | ------ | -------- | ------ | -------------- | 
| 1        | 60  | 22  | 1      | 0        | 0      | Oviedo         |
| 2        | 40  | 30  | 0      | 1        | 0      | Sanford        |
| 3        | 25  | 25  | 0      | 0        | 1      | Winter Park    |
| 4        | 33  | 35  | 1      | 2        | 0      | Winter Springs |
| 5        | 45  | 27  | 1      | 3        | 0      | Oviedo         |


```{r q7}

potential1 <- data.frame(Age = 60,
                            BMI = 22,
                            Children = 0,
                            Female = 1,
                            Smoker = 0,
                            WinterSprings = 0,
                            WinterPark = 0,
                            Oviedo = 1)
potential2 <- data.frame(Age = 40,
                            BMI = 30,
                            Children = 1,
                            Female = 0,
                            Smoker = 0,
                            WinterSprings = 0,
                            WinterPark = 0,
                            Oviedo = 1)
potential3 <- data.frame(Age = 25,
                            BMI = 25,
                            Children = 0,
                            Female = 0,
                            Smoker = 1,
                            WinterSprings = 0,
                            WinterPark = 1,
                            Oviedo = 0)
potential4 <- data.frame(Age = 33,
                            BMI = 35,
                            Children = 2,
                            Female = 1,
                            Smoker = 0,
                            WinterSprings = 1,
                            WinterPark = 0,
                            Oviedo = 0)
potential5 <- data.frame(Age = 45,
                            BMI = 27,
                            Children = 3,
                            Female = 1,
                            Smoker = 0,
                            WinterSprings = 0,
                            WinterPark = 0,
                            Oviedo = 1)

predict(model, newdata = potential1, interval = 'prediction')
predict(model, newdata = potential2, interval = 'prediction')
predict(model, newdata = potential3, interval = 'prediction')
predict(model, newdata = potential4, interval = 'prediction')
predict(model, newdata = potential5, interval = 'prediction')
```


## Question 8

The owner notices that some of the predictions are wider than others, explain why.

Some predictions are wider than others due to the independent variables being farther from the means of the sample observations. 

## Question 9 

Are there any prediction problems that occur with the five potential clients? If so, explain.

Yes, there are prediction problems as can be seen from the negative charges. This is due to modeling error and specification bias. 